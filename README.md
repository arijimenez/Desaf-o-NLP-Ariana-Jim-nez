
# 游늷 An치lisis de Emociones en Tweets en Espa침ol  

Este proyecto implementa distintos enfoques de **Procesamiento de Lenguaje Natural (NLP)** para la clasificaci칩n de emociones en textos en espa침ol, utilizando el dataset [EmoEvent](https://github.com/fmplaza/EmoEvent), que contiene m치s de **8,000 tweets** anotados en categor칤as como:  
`anger, joy, sadness, fear, disgust, surprise, others`.  

---

## 游 Objetivo  
Evaluar y comparar el rendimiento de diferentes modelos para la **detecci칩n autom치tica de emociones en espa침ol**, desde arquitecturas cl치sicas entrenadas desde cero hasta modelos de 칰ltima generaci칩n preentrenados.

---

## 丘뙖잺 Modelos implementados  

1. **游댳 LSTM (baseline entrenado desde cero)**  
   - Red neuronal recurrente con embeddings.  
   - Accuracy: **~51%**.  
   - Problemas: fuerte *overfitting* y bajo rendimiento en clases minoritarias.  

2. **游댳 DistilBERT (fine-tuning en ingl칠s)**  
   - Modelo preentrenado en grandes corpus, ajustado para clasificaci칩n de emociones.  
   - Accuracy: **~64%**.  
   - Mejor generalizaci칩n y balance entre clases.  

3. **游댳 Robertuito (pysentimiento/robertuito-emotion-analysis)**  
   - Variante de RoBERTa preentrenada en **espa침ol** y especializada en **detecci칩n de emociones**.  
   - Accuracy: **~86%**, F1 ponderado: **0.85**.  
   - Excelente en clases dominantes, aunque *disgust* sigue siendo dif칤cil por el desbalance del dataset.  

---

## 游늵 Resultados  

| Modelo      | Accuracy | F1-Score Ponderado | Observaciones |
|-------------|----------|--------------------|---------------|
| **LSTM**        | 0.51     | 0.39               | Baseline, sobreajuste, bajo desempe침o en clases minoritarias. |
| **DistilBERT**  | 0.64     | 0.61               | Mejora gracias a transfer learning, m치s equilibrado. |
| **Robertuito**  | 0.86     | 0.85               | Mejor modelo, especializado en emociones en espa침ol. |

---
## Matrices de confusi칩n
La matriz de confusi칩n del modelo LSTM revela que las clases con mayor cantidad de datos, como *others*, *joy* y *sadness*, alcanzan un rendimiento aceptable con 437, 201 y 130 aciertos respectivamente, aunque presentan confusiones relevantes: *others* se confunde en 200 casos con *joy*, esta 칰ltima en m치s de 100 casos con *others* y en 25 con *sadness*, mientras que *anger*, con 63 aciertos, suele confundirse con *sadness* (40 casos) y *others* (23 casos). En el caso de las clases minoritarias, el desempe침o es muy bajo: *fear* apenas logra 6 aciertos y 9 confusiones en *others*, *disgust* tambi칠n 6 aciertos pero dispersos en varias clases, y *surprise* solo 13 aciertos con 34 errores hacia *others*. En conjunto, esto muestra que el modelo funciona razonablemente bien en las clases dominantes, pero fracasa en distinguir emociones minoritarias y confunde emociones cercanas sem치nticamente, lo que explica su bajo rendimiento general (\~50% de accuracy) y confirma sus limitaciones frente al desbalance de datos.
<img width="785" height="624" alt="image" src="https://github.com/user-attachments/assets/c83daf4b-0d49-4683-ac6e-4541215fb0b1" />

La matriz de confusi칩n muestra que tu modelo DistilBERT fine-tuneado tiene un buen desempe침o en clases mayoritarias como others, joy y sadness, pero presenta un fuerte sesgo hacia la clase others, absorbiendo muchos errores de las dem치s categor칤as. Emociones minoritarias como disgust, fear y surprise casi no son reconocidas, lo que refleja un claro desbalance en el dataset. En general, el modelo distingue razonablemente bien emociones frecuentes, pero necesita estrategias como balanceo de datos, ponderaci칩n de clases o data augmentation para mejorar el reconocimiento de las clases menos representadas.
<img width="554" height="468" alt="image" src="https://github.com/user-attachments/assets/51a010cb-f176-454f-9dc2-21d75f715c36" />

En esta tercera matriz de confusi칩n, del modelo pysentimiento/robertuito-emotion-analysis entrenado en espa침ol, se observa un rendimiento m치s equilibrado que en tu modelo DistilBERT fine-tuneado y en el LSTM. La clase others sigue siendo la m치s dominante (3736 aciertos), pero a diferencia del anterior, aqu칤 las emociones principales como joy (1562), sadness (876) y anger (757) se reconocen con mucha mayor precisi칩n y menos confusi칩n hacia others. Adem치s, emociones dif칤ciles como surprise (220), disgust (132) y fear (75) tambi칠n son identificadas, aunque con menor volumen de datos. En general, este modelo presenta mejor capacidad para distinguir entre emociones, mostrando menos sesgo hacia la clase mayoritaria y una cobertura m치s amplia de las categor칤as minoritarias.
<img width="751" height="590" alt="image" src="https://github.com/user-attachments/assets/fe9ef47f-fa4c-4cc2-8cd9-b64b38227061" />


## 游댌 Conclusiones  

- Los **modelos preentrenados** superan ampliamente a modelos entrenados desde cero.  
- **Robertuito** es la opci칩n ideal para aplicaciones reales en **an치lisis de emociones en redes sociales en espa침ol**, gracias a su rapidez, precisi칩n y especializaci칩n.  
- El **desbalance de clases** sigue siendo un reto, especialmente para emociones como *disgust, fear, surprise*.  

---

## 游늭 Puede revisar el c칩digo en el siguiente enlace:
https://colab.research.google.com/drive/1UnVamXla36SLW6J9ciOkfXipQI2AmuDi?usp=sharing  

